# -*- coding: utf-8 -*-
"""Untitled8d.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xbQTL-IQI_8jZISZuuOI5zMkHvpVGO9P
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
# Load Fashion-MNIST dataset

import torchvision

# C part with early stopping
transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])
full_train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)

# Split the full training dataset into train and validation
train_size = int(0.8 * len(full_train_dataset))  # 80% for training, 20% for validation
val_size = len(full_train_dataset) - train_size
train_dataset, validation_dataset = torch.utils.data.random_split(full_train_dataset, [train_size, val_size])

# DataLoaders for training, validation, and test
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)
validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=256, shuffle=False)
test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)



# Define the ResNet-18 model
model = torchvision.models.resnet18(pretrained=False)
model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
model.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
model.fc = nn.Linear(512, 10)

# Define optimizer and loss function and weight decay
criterion = nn.CrossEntropyLoss()
optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# Early stopping parameters
patience = 3  # Number of epochs with no improvement after which to stop
best_val_loss = float('inf')
counter = 0

# Training the model
train_accuracy, test_accuracy = [], []
epochs = 5

for epoch in range(epochs):
    model.train()
    correct_train, total_train = 0, 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        _, predicted = torch.max(outputs, 1)
        correct_train += (predicted == labels).sum().item()
        total_train += labels.size(0)

    # Validation
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for val_images, val_labels in validation_loader:
            val_images, val_labels = val_images.to(device), val_labels.to(device)
            val_outputs = model(val_images)
            val_loss += criterion(val_outputs, val_labels).item()

    val_loss /= len(validation_loader)

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        counter = 0
    else:
        counter += 1

    if counter >= patience:
        print(f"Early stopping at epoch {epoch}. Validation loss: {best_val_loss}")
        break


    train_acc = correct_train / total_train
    train_accuracy.append(train_acc)

    # model.eval()
    correct_test, total_test = 0, 0

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            correct_test += (predicted == labels).sum().item()
            total_test += labels.size(0)

    test_acc = correct_test / total_test
    test_accuracy.append(test_acc)

    print(f"Epoch [{epoch + 1}/{epochs}], Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}")

# Plotting training and test accuracy curves
plt.plot(train_accuracy, label='Training Accuracy')
plt.plot(test_accuracy, label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

